{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the automated ML generated model using model explainability \n",
    "In this notebook, you will retrieve the best model from the automated machine learning experiment you performed previously. Then you will use the model interpretability features of the Azure Machine Learning Python SDK to indentify which features had the most impact on the prediction.\n",
    "\n",
    "**Please be sure you have completed Exercise 1 before continuing**\n",
    "\n",
    "Begin by running the following cell to ensure your environment has the required modules installed and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azureml-interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run the following cell to import all the modules used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.10g}'.format\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Run\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Model\n",
    "from azureml.core import Experiment\n",
    "\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "\n",
    "from azureml.train.automl.automl_explain_utilities import AutoMLExplainerSetupClass, automl_setup_model_explanations\n",
    "from interpret_community.mimic.models import LGBMExplainableModel\n",
    "from azureml.interpret.mimic_wrapper import MimicWrapper\n",
    "from azureml.contrib.interpret.visualize import ExplanationDashboard\n",
    "from azureml.contrib.interpret.explanation.explanation_client import ExplanationClient\n",
    "\n",
    "# Verify AML SDK Installed\n",
    "# view version history at https://pypi.org/project/azureml-sdk/#history \n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure access to your Azure Machine Learning Workspace\n",
    "To begin, you will need to provide the following information about your Azure Subscription.\n",
    "\n",
    "**If you are using your own Azure subscription, please provide names for subscription_id, resource_group, workspace_name and workspace_region to use.** Note that the workspace needs to be of type [Machine Learning Workspace](https://docs.microsoft.com/en-us/azure/machine-learning/service/setup-create-workspace).\n",
    "\n",
    "**If an environment is provided to you be sure to replace XXXXX in the values below with your unique identifier.**\n",
    "\n",
    "In the following cell, be sure to set the values for `subscription_id`, `resource_group`, `workspace_name` and `workspace_region` as directed by the comments (*these values can be acquired from the Azure Portal*).\n",
    "\n",
    "To get these values, do the following:\n",
    "1. Navigate to the Azure Portal and login with the credentials provided.\n",
    "2. From the left hand menu, under Favorites, select `Resource Groups`.\n",
    "3. In the list, select the resource group with the name similar to `tech_immersion_XXXXXimmersion_XXXXX`.\n",
    "4. From the Overview tab, capture the desired values.\n",
    "\n",
    "Execute the following cell by selecting the `>|Run` button in the command bar above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the Subscription ID of your existing Azure subscription\n",
    "subscription_id = \"\" # <- needs to be the subscription with the resource group\n",
    "\n",
    "#Provide values for the existing Resource Group \n",
    "resource_group = \"tech_immersion_XXXXX\" # <- replace XXXXX with your unique identifier\n",
    "\n",
    "#Provide the Workspace Name and Azure Region of the Azure Machine Learning Workspace\n",
    "workspace_name = \"tech_immersion_aml_XXXXX\" # <- replace XXXXX with your unique identifier (should be lowercase)\n",
    "workspace_region = \"eastus2\" # <- region of your resource group\n",
    "\n",
    "#Provide the name of the Experiment you used with Automated Machine Learning\n",
    "experiment_name = 'automl-regression'\n",
    "\n",
    "# the train data is available here\n",
    "train_data_url = ('https://quickstartsws9073123377.blob.core.windows.net/'\n",
    "                  'azureml-blobstore-0d1c4218-a5f9-418b-bf55-902b65277b85/'\n",
    "                  'training-formatted.csv')\n",
    "\n",
    "# this is the URL to the CSV file containing a small set of test data\n",
    "test_data_url = ('https://quickstartsws9073123377.blob.core.windows.net/'\n",
    "                  'azureml-blobstore-0d1c4218-a5f9-418b-bf55-902b65277b85/'\n",
    "                  'fleet-formatted.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Azure Machine Learning Workspace\n",
    "\n",
    "Run the following cell to connect the Azure Machine Learning **Workspace**.\n",
    "\n",
    "**Important Note**: You will be prompted to login in the text that is output below the cell. Be sure to navigate to the URL displayed and enter the code that is provided. Once you have entered the code, return to this notebook and wait for the output to read `Workspace Provisioning complete`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using the exist_ok param, if the worskpace already exists we get a reference to the existing workspace\n",
    "ws = Workspace.create(\n",
    "    name = workspace_name,\n",
    "    subscription_id = subscription_id,\n",
    "    resource_group = resource_group, \n",
    "    location = workspace_region,\n",
    "    exist_ok = True)\n",
    "\n",
    "print(\"Workspace Provisioning complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the run id of your Automated ML experiment in the Azure Machine Learning studio\n",
    "\n",
    "In the following cell, be sure to set the value for `run_id` as directed by the comments (*this value can be acquired from the Azure Machine Learning Portal*).\n",
    "To get these values, do the following:\n",
    "1. Navigate to your Azure Machine Learning workspace in the Azure Portal and login with the credentials provided.\n",
    "2. From the left navigation bar select `Overwiew` and then select `Launch the Azure Machine Learning studio`.\n",
    "3. From the left navigation bar select `Experiments` and then identify the first run in the `automl-regression` experiment at the bottom of the run list. This should be have `Run 1` in the `Run` column and `automl` in the `Run type` column.\n",
    "4. Click on `Run 1` link to open the run details screen where you can capture the `Run ID` value which should be an identifier starting with `AutoML_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the Run Id of the automl type run in your experiment \n",
    "run_id = 'AutoML_....'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the best model trained with automated machine learning\n",
    "\n",
    "Retrieve the Run from the Experiment and then get the underlying AutoMLRun to get at the best model and child run objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_experiment = Experiment(ws,experiment_name)\n",
    "\n",
    "automl_run = AutoMLRun(existing_experiment, run_id)\n",
    "automl_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the best run and best model from the automated machine learning run by executing the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import azureml.automl\n",
    "best_run, best_model = automl_run.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the train and test data\n",
    "\n",
    "Model interpretability works by passing training and test data thru the created model and evaluating the result of which values had a given impact. \n",
    "\n",
    "Load the training and test data by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original training data\n",
    "train_data = pd.read_csv(train_data_url)\n",
    "X_train = train_data.iloc[:,1:74]\n",
    "y_train = train_data.iloc[:,0].values.flatten()\n",
    "\n",
    "# load some test vehicle data that the model has not seen\n",
    "X_test = pd.read_csv(test_data_url)\n",
    "X_test = X_test.drop(columns=[\"Car_ID\", \"Battery_Age\"])\n",
    "X_test.rename(columns={'Twelve_hourly_temperature_forecast_for_next_31_days_reversed': 'Twelve_hourly_temperature_history_for_last_31_days_before_death_last_recording_first'}, inplace=True)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Get the explanations for each model produced by the Automated ML experiment\n",
    "\n",
    "For automated machine learning models, you can use `ExplanationClient` to examine the features that were most impactful to the model.\n",
    "\n",
    "The best run already has explanations computed, so we only need to download them. For all other models, we need to calculate the explanations on the spot. The `LGBMExplainableModel` is used to mimic the behavor of each trained model.\n",
    "Run the following cell perform the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explanation_dataframe(model_name, is_best, feature_dict):\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(list(feature_dict.keys()), list(feature_dict.values()))), dtype=float,\n",
    "                     columns=['FeatureName', 'FeatureImportance'])\n",
    "    df['ModelName'] = model_name\n",
    "    df['IsBest'] = is_best\n",
    "    \n",
    "    print(df.columns)\n",
    "    return df\n",
    "\n",
    "explanation_df = pd.DataFrame(columns=['ModelName', 'IsBest', 'FeatureName', 'FeatureImportance'])\n",
    "\n",
    "for child_run in list(automl_run.get_children()):\n",
    "    grand_child_runs = list(child_run.get_children())\n",
    "    \n",
    "    needs_explanation = True\n",
    "    if len(grand_child_runs) > 0:\n",
    "        \n",
    "        #attempt to find an explainability run\n",
    "        \n",
    "        explain_runs = list(filter(lambda x: x.type == 'automl.model_explain', grand_child_runs))\n",
    "        if len(explain_runs) > 0:\n",
    "            needs_explanation = False\n",
    "            \n",
    "    if needs_explanation:\n",
    "        print('Creating explanation for model {}...'.format(child_run.id))\n",
    "\n",
    "        iteration = child_run.properties['iteration']\n",
    "        iteration_run, iteration_model = automl_run.get_output(iteration=iteration)\n",
    "        \n",
    "        automl_explainer_setup_obj = automl_setup_model_explanations(iteration_model, X=X_train, \n",
    "                                                             X_test=X_test, y=y_train, \n",
    "                                                             task='regression')\n",
    "        \n",
    "        explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator, LGBMExplainableModel, \n",
    "                         init_dataset=automl_explainer_setup_obj.X_transform, run=automl_run,\n",
    "                         features=automl_explainer_setup_obj.engineered_feature_names, \n",
    "                         feature_maps=[automl_explainer_setup_obj.feature_map],\n",
    "                         classes=automl_explainer_setup_obj.classes)\n",
    "        \n",
    "        raw_explanations = explainer.explain(['local', 'global'], get_raw=True, \n",
    "                                     raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n",
    "                                     eval_dataset=automl_explainer_setup_obj.X_test_transform)\n",
    "\n",
    "        features_dict = raw_explanations.get_feature_importance_dict()\n",
    "        features_df = get_explanation_dataframe(child_run.id, False, feature_dict)\n",
    "         \n",
    "    else:\n",
    "        print ('Model {} has already an explanation.'.format(child_run.id))\n",
    "        \n",
    "        client = ExplanationClient.from_run(child_run)\n",
    "        engineered_explanations = client.download_model_explanation(raw=False)\n",
    "        feature_dict = engineered_explanations.get_feature_importance_dict()\n",
    "        \n",
    "        features_df = get_explanation_dataframe(child_run.id, True, feature_dict)\n",
    "\n",
    "    explanation_df = pd.concat([explanation_df, features_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to render the feature importance of the `best model` using the features Pandas DataFrame created above. Which feature had the greatest importance globally on the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the feature importances for the best model\n",
    "explanation_df[explanation_df.IsBest == True].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Display the explanation dashboard for the best model\n",
    "\n",
    "The following command must be run to activate the dashboard in Jupyter notebooks.\n",
    "\n",
    "Note: If the dashboard does not display, you might need to refresh the content in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_explainer_setup_obj = automl_setup_model_explanations(best_model, X=X_train, \n",
    "                                                             X_test=X_test, y=y_train, \n",
    "                                                             task='regression')\n",
    "        \n",
    "explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator, LGBMExplainableModel, \n",
    "                 init_dataset=automl_explainer_setup_obj.X_transform, run=automl_run,\n",
    "                 features=automl_explainer_setup_obj.engineered_feature_names, \n",
    "                 feature_maps=[automl_explainer_setup_obj.feature_map],\n",
    "                 classes=automl_explainer_setup_obj.classes)\n",
    "\n",
    "raw_explanations = explainer.explain(['local', 'global'], get_raw=True, \n",
    "                             raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n",
    "                             eval_dataset=automl_explainer_setup_obj.X_test_transform)\n",
    "\n",
    "ExplanationDashboard(raw_explanations, automl_explainer_setup_obj.automl_pipeline, automl_explainer_setup_obj.X_test_raw)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}